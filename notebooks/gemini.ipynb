{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      VersionNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "---------------------------- -----------\n",
      "absl-py                      2.1.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "backcall                     0.2.0\n",
      "beautifulsoup4               4.12.3\n",
      "blinker                      1.7.0\n",
      "bs4                          0.0.2\n",
      "cachetools                   5.3.3\n",
      "certifi                      2024.2.2\n",
      "charset-normalizer           3.3.2\n",
      "click                        8.1.7\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.1\n",
      "debugpy                      1.8.1\n",
      "decorator                    5.1.1\n",
      "executing                    2.0.1\n",
      "Flask                        3.0.2\n",
      "flatbuffers                  23.5.26\n",
      "gast                         0.4.0\n",
      "google-ai-generativelanguage 0.1.0\n",
      "google-api-core              2.17.1\n",
      "google-auth                  2.28.1\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-generativeai          0.1.0rc1\n",
      "google-pasta                 0.2.0\n",
      "googleapis-common-protos     1.62.0\n",
      "grpcio                       1.62.0\n",
      "grpcio-status                1.48.2\n",
      "h5py                         3.10.0\n",
      "idna                         3.6\n",
      "importlib-metadata           7.0.1\n",
      "ipykernel                    6.29.3\n",
      "ipython                      8.12.3\n",
      "itsdangerous                 2.1.2\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.3\n",
      "joblib                       1.3.2\n",
      "jupyter_client               8.6.0\n",
      "jupyter_core                 5.7.1\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "libclang                     16.0.6\n",
      "Markdown                     3.5.2\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib-inline            0.1.6\n",
      "nest-asyncio                 1.6.0\n",
      "nltk                         3.8.1\n",
      "numpy                        1.24.4\n",
      "oauthlib                     3.2.2\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    23.2\n",
      "parso                        0.8.3\n",
      "pickleshare                  0.7.5\n",
      "pillow                       10.2.0\n",
      "pip                          24.0\n",
      "platformdirs                 4.2.0\n",
      "prompt-toolkit               3.0.43\n",
      "proto-plus                   1.23.0\n",
      "protobuf                     3.19.6\n",
      "psutil                       5.9.8\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.1\n",
      "pyasn1-modules               0.3.0\n",
      "Pygments                     2.17.2\n",
      "python-dateutil              2.9.0.post0\n",
      "pywin32                      306\n",
      "pyzmq                        25.1.2\n",
      "regex                        2023.12.25\n",
      "requests                     2.31.0\n",
      "requests-oauthlib            1.3.1\n",
      "rsa                          4.9\n",
      "scikit-learn                 1.3.2\n",
      "scipy                        1.10.1\n",
      "setuptools                   69.0.3\n",
      "six                          1.16.0\n",
      "soupsieve                    2.5\n",
      "stack-data                   0.6.3\n",
      "tensorboard                  2.10.1\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.10.0\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.4.0\n",
      "threadpoolctl                3.3.0\n",
      "tornado                      6.4\n",
      "tqdm                         4.66.2\n",
      "traitlets                    5.14.1\n",
      "typing_extensions            4.10.0\n",
      "urllib3                      2.2.1\n",
      "wcwidth                      0.2.13\n",
      "Werkzeug                     3.0.1\n",
      "wheel                        0.42.0\n",
      "wrapt                        1.16.0\n",
      "zipp                         3.17.0\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\codes\\Python\\Product_ranking\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Bread\n",
      "2. Brown\n",
      "3. Amul\n",
      "4. Whole wheat\n",
      "5. Fiber\n",
      "6. Healthy\n",
      "7. Nutritious\n",
      "8. Rich\n",
      "9. Soft\n",
      "10. Fresh\n",
      "11. Delicious\n",
      "12. Breakfast\n",
      "13. Snack\n",
      "14. Toast\n",
      "15. Sandwich\n",
      "16. Protein\n",
      "17. Vitamins\n",
      "18. Minerals\n",
      "19. Iron\n",
      "20. Calcium\n",
      "21. Oven-baked\n",
      "22. No preservatives\n",
      "23. No artificial colors\n",
      "24. No artificial flavors\n",
      "25. Vegetarian\n",
      "26. Dairy\n",
      "27. Indian\n",
      "28. Authentic\n",
      "29. Traditional\n",
      "30. Wholesome\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace(\"â€¢\", \"  *\")\n",
    "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBkheEuRdAh4xULrOz-g1GveaIv8RZkka8\")\n",
    "# for m in genai.list_models():\n",
    "#     if \"generateContent\" in m.supported_generation_methods:\n",
    "#         print(m.name)\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "product = \"Amul Brown Bread\"\n",
    "response = model.generate_content(\n",
    "    f\"Give the 30 most relevant one word keywords for the product {product} that should be put in the product description on e-commerce.\"\n",
    ")\n",
    "\n",
    "x = response.text\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"co.txt\", \"w\") as f:\n",
    "    f.write(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import google.generativeai as genai\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize words and remove punctuation\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "def calculate_relevance(product, refined_description, relevant_words):\n",
    "    # Create a corpus of words from the refined description\n",
    "    description_words = set(refined_description.split())\n",
    "\n",
    "    # Calculate the number of relevant words present in the description\n",
    "    relevant_words_in_description = relevant_words.intersection(description_words)\n",
    "\n",
    "    # Calculate percentage relevance\n",
    "    relevance_percentage = (\n",
    "        len(relevant_words_in_description) / len(relevant_words)\n",
    "    ) * 100\n",
    "\n",
    "    return relevance_percentage\n",
    "\n",
    "\n",
    "def generate_relevant_words(product, num_words=30):\n",
    "\n",
    "    # List of words (random example)\n",
    "    word_list = []\n",
    "\n",
    "    # Randomly select num_words from the list\n",
    "    relevant_words = set([\"hello\", \"butter\", \"nice\", \"rice\", \"taste\"])  # ai gen\n",
    "\n",
    "    return relevant_words\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input for product name\n",
    "    product = input(\"Enter the product descriptions: \")\n",
    "\n",
    "    ## Fetch relevant words using a list of words\n",
    "    relevant_words = generate_relevant_words(product)\n",
    "    print(\"Relevant words:\", relevant_words)\n",
    "\n",
    "    # Refine description\n",
    "    wiki_text = \"\"\n",
    "    preprocessed_text = preprocess_text(wiki_text)\n",
    "    refined_description = \" \".join(preprocessed_text)\n",
    "\n",
    "    # Calculate the relevance of the relevant words to the description\n",
    "    relevance_percentage = calculate_relevance(\n",
    "        product, refined_description, relevant_words\n",
    "    )\n",
    "    print(\n",
    "        f\"The relevance percentage of the description to the product is: {relevance_percentage:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_desc = \"Spread the goodness of India with Amul Butter! Crafted from the rich milk of happy cows, Amul butter delivers a pure, creamy taste that elevates every dish. Its delightful golden texture is perfect for toast, parathas, or melting into your favorite curries. Made with traditional methods and the promise of quality, Amul Butter is a wholesome and versatile addition to your kitchen, bringing a touch of everyday indulgence to every meal.\"\n",
    "\n",
    "sample_product = \"Amul Butter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import google.generativeai as genai\n",
    "# from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def reduce_desc(desc):\n",
    "    words = word_tokenize(desc)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "    ps = PorterStemmer()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [ps.stem(word.lower()) for word in words if word not in stop_words]\n",
    "\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "def generate_keywords(product_name):\n",
    "    genai.configure(api_key=\"AIzaSyBkheEuRdAh4xULrOz-g1GveaIv8RZkka8\")\n",
    "    ps = PorterStemmer()\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    product = product_name\n",
    "    response = model.generate_content(\n",
    "        f\"Give the 30 words for the product {sample_product} that should be present in it's description. Give space separated words\"\n",
    "    )\n",
    "    time.sleep(3)\n",
    "    x = response.text\n",
    "    print(x)\n",
    "    # Split the string into a list using newline character as separator\n",
    "    word_list = x.split(\" \")\n",
    "    word_list = [ps.stem(word.lower()) for word in word_list]\n",
    "    # Remove any elements containing digits using list comprehension\n",
    "\n",
    "    print(word_list)\n",
    "    return word_list\n",
    "\n",
    "\n",
    "def relevance_coeff(desc_keys, gen_keys):\n",
    "    # Create a corpus of words from the refined description\n",
    "    description_words = set(desc_keys)\n",
    "    print(description_words)\n",
    "    # description_words = set(desc_keys)\n",
    "\n",
    "    # Calculate the number of relevant words present in the description\n",
    "    relevant_words_in_description = description_words.intersection(gen_keys)\n",
    "\n",
    "    # Calculate percentage relevance\n",
    "    relevance_percentage = (\n",
    "        len(relevant_words_in_description) / len(gen_keys)\n",
    "    ) * 100\n",
    "\n",
    "    return relevance_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creamy Rich Golden Pure Fresh Salted Unsalted Spreadable Versatile Baking Cooking BakingSpreadable Gourmet Classic Cultured EuropeanAwardWinning Authentic Traditional Indian DairyDeliciousHealthy Natural PremiumNutrientRichInnovative WholesomeGoodness\n",
      "['creami', 'rich', 'golden', 'pure', 'fresh', 'salt', 'unsalt', 'spreadabl', 'versatil', 'bake', 'cook', 'bakingspread', 'gourmet', 'classic', 'cultur', 'europeanawardwin', 'authent', 'tradit', 'indian', 'dairydelicioushealthi', 'natur', 'premiumnutrientrichinnov', 'wholesomegood']\n",
      "{'spread', 'elev', 'touch', 'happi', 'method', 'paratha', 'everi', 'versatil', 'made', 'butter', 'favorit', 'golden', 'indulg', 'everyday', 'dish', 'delight', 'milk', 'deliv', 'promis', 'cow', 'kitchen', 'amul', 'melt', 'qualiti', 'meal', 'good', 'craft', 'textur', 'rich', 'perfect', 'toast', 'creami', 'addit', 'wholesom', 'tradit', 'india', 'bring', 'pure', 'tast', 'curri'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.08695652173913"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(reduce_desc(sample_desc)) \n",
    "# print(generate_keywords(sample_product))\n",
    "\n",
    "# Amul Butter\n",
    "relevance_coeff(reduce_desc(sample_desc), generate_keywords(sample_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creamy, Rich, Golden, Smooth, Spreadable, Versatile, All-Natural, Premium, Unsalted, Salted, Churned, Cultured, Homogenized, Vitamin A, Vitamin D, Cholesterol-Free, Trans Fat-Free, Gluten-Free, Non-GMO, Kosher, Halal, Lactose-Free, Whey-Free, Casein-Free, Soy-Free, Nut-Free, Gluten-Free, Preservative-Free, Artificial Flavor-Free, Artificial Color-Free\n",
      "['creamy,', 'rich,', 'golden,', 'smooth,', 'spreadable,', 'versatile,', 'all-natural,', 'premium,', 'unsalted,', 'salted,', 'churned,', 'cultured,', 'homogenized,', 'vitamin', 'a,', 'vitamin', 'd,', 'cholesterol-free,', 'tran', 'fat-free,', 'gluten-free,', 'non-gmo,', 'kosher,', 'halal,', 'lactose-free,', 'whey-free,', 'casein-free,', 'soy-free,', 'nut-free,', 'gluten-free,', 'preservative-free,', 'artifici', 'flavor-free,', 'artifici', 'color-fre']\n",
      "{'spread', 'elev', 'touch', 'happi', 'method', 'paratha', 'everi', 'versatil', 'made', 'butter', 'favorit', 'golden', 'indulg', 'everyday', 'dish', 'delight', 'milk', 'deliv', 'promis', 'cow', 'kitchen', 'amul', 'melt', 'qualiti', 'meal', 'good', 'craft', 'textur', 'rich', 'perfect', 'toast', 'creami', 'addit', 'wholesom', 'tradit', 'india', 'bring', 'pure', 'tast', 'curri'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amul Milk product\n",
    "relevance_coeff(reduce_desc(sample_desc), generate_keywords(sample_product))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
